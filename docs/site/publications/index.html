<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
    <title>Publications - Anuroop Sriram</title>
  
  
  
    <meta name="description" content="Personal webpage of Anuroop Sriram">
  
  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
  <link rel="stylesheet" href="../static/css/main.css">
  <link rel="canonical" href="/publications/">
  <link rel="shortcut icon" type="image/x-icon" href="../static/favicon.ico">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

  
</head>
  <body>
    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">Anuroop Sriram</a>
    </div>
    <div class="collapse navbar-collapse" id="navbar-collapse-1">
      <ul class="nav navbar-nav navbar-right">
        <li><a href="../index.html">Home</a></li>
        <li><a href="index.html">Publications</a></li>
        <li><a href="../datasets/index.html">Datasets</a></li>
        <li>
          <button class="theme-toggle" onclick="toggleTheme()" aria-label="Toggle dark mode">
            <span id="theme-icon">üåô</span>
          </button>
        </li>
      </ul>
    </div>
  </div>
</div>
    
    <div class="container-fluid">
      <div class="row">
        
<div id="gridid" class="col-sm-12">
  
<h1>Publications</h1>


  
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
      <h2>2025</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/fastcsp25.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> FastCSP: Accelerated Molecular Crystal Structure Prediction with Universal Model for Atoms</strong> <br />
  <em><small>Vahe Gharakhanyan, Yi Yang, Luis Barroso-Luque, Muhammed Shuaibi, Daniel S. Levine, Kyle Michel, Viachaslau Bernat, Misko Dzamba, Xiang Fu, Meng Gao, Xingyu Liu, Keian Noori, Lafe J. Purvis, Tingling Rao, Brandon M. Wood, Ammar Rizvi, Matt Uyttendaele, Andrew J. Ouderkirk, Chiara Daraio, C. Lawrence Zitnick, Arman Boromand, Noa Marom, Zachary W. Ulissi, Anuroop Sriram </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2508.02641" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#fastcsp25_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="fastcsp25_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="fastcsp25_abs"><div class="well-abstract">
<small> <p align="justify"> Crystal Structure Prediction (CSP) of molecular crystals plays a central role in applications, such as pharmaceuticals and organic electronics. CSP is challenging and computationally expensive due to the need to explore a large search space with sufficient accuracy to capture energy differences of a few kJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT) provides the required accuracy but its computational cost is impractical for a large number of putative structures. We introduce FastCSP, an open-source, high-throughput CSP workflow based on machine learning interatomic potentials (MLIPs). FastCSP combines random structure generation using Genarris 3.0 with geometry relaxation and free energy calculations powered entirely by the Universal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of 28 mostly rigid molecules, demonstrating that our workflow consistently generates known experimental structures and ranks them within 5 kJ/mol per molecule of the global minimum. Our results demonstrate that universal MLIPs can be used across diverse compounds without requiring system-specific tuning. Moreover, the speed and accuracy afforded by UMA eliminate the need for classical force fields in the early stages of CSP and for final re-ranking with DFT. The open-source release of the entire FastCSP workflow significantly lowers the barrier to accessing CSP. CSP results for a single system can be obtained within hours on tens of modern GPUs, making high-throughput crystal structure prediction feasible for a broad range of scientific applications. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/odac25.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> The Open DAC 2025 Dataset for Sorbent Discovery in Direct Air Capture</strong> <br />
  <em><small>Anuroop Sriram, Logan M. Brabson, Xiaohan Yu, Sihoon Choi, Kareem Abdelmaqsoud, Elias Moubarak, Pim de Haan, Sindy L√∂we, Johann Brehmer, John R. Kitchin, Max Welling, C. Lawrence Zitnick, Zachary Ulissi, Andrew J. Medford, David S. Sholl </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2508.03162" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#odac25_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="odac25_abs">ABSTRACT</a>
  
  <a href="https://huggingface.co/facebook/ODAC25" target="_blank"><button class="btn-common">DATA</button></a> 
  <a href="https://huggingface.co/facebook/ODAC25" target="_blank"><button class="btn-common">MODELS</button></a> 
  


<br/>
<div class="collapse" id="odac25_abs"><div class="well-abstract">
<small> <p align="justify"> Identifying useful sorbent materials for direct air capture (DAC) from humid air remains a challenge. We present the Open DAC 2025 (ODAC25) dataset, a significant expansion and improvement upon ODAC23 (Sriram et al., ACS Central Science, 10 (2024) 923), comprising nearly 70 million DFT single-point calculations for CO2, H2O, N2, and O2 adsorption in 15,000 MOFs. ODAC25 introduces chemical and configurational diversity through functionalized MOFs, high-energy GCMC-derived placements, and synthetically generated frameworks. ODAC25 also significantly improves upon the accuracy of DFT calculations and the treatment of flexible MOFs in ODAC23. Along with the dataset, we release new state-of-the-art machine-learned interatomic potentials trained on ODAC25 and evaluate them on adsorption energy and Henry&#39;s law coefficient predictions. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/omc25.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Open Molecular Crystals 2025 (OMC25) Dataset and Models</strong> <br />
  <em><small>Vahe Gharakhanyan, Luis Barroso-Luque, Yi Yang, Muhammed Shuaibi, Kyle Michel, Daniel S. Levine, Misko Dzamba, Xiang Fu, Meng Gao, Xingyu Liu, Haoran Ni, Keian Noori, Brandon M. Wood, Matt Uyttendaele, Arman Boromand, C. Lawrence Zitnick, Noa Marom, Zachary W. Ulissi, Anuroop Sriram </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2508.02651" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#omc25_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="omc25_abs">ABSTRACT</a>
  
  <a href="https://huggingface.co/facebook/OMC25" target="_blank"><button class="btn-common">DATA</button></a> 
  <a href="https://huggingface.co/facebook/OMC25" target="_blank"><button class="btn-common">MODELS</button></a> 
  


<br/>
<div class="collapse" id="omc25_abs"><div class="well-abstract">
<small> <p align="justify"> The development of accurate and efficient machine learning models for predicting the structure and properties of molecular crystals has been hindered by the scarcity of publicly available datasets of structures with property labels. To address this challenge, we introduce the Open Molecular Crystals 2025 (OMC25) dataset, a collection of over 27 million molecular crystal structures containing 12 elements and up to 300 atoms in the unit cell. The dataset was generated from dispersion-inclusive density functional theory (DFT) relaxation trajectories of over 230,000 randomly generated molecular crystal structures of around 50,000 organic molecules. OMC25 comprises diverse chemical compounds capable of forming different intermolecular interactions and a wide range of crystal packing motifs. We provide detailed information on the dataset&#39;s construction, composition, structure, and properties. To demonstrate the quality and use cases of OMC25, we further trained and evaluated state-of-the-art open-source machine learning interatomic potentials. By making this dataset publicly available, we aim to accelerate the development of more accurate and efficient machine learning models for molecular crystals. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/wood2025Uma.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> UMA: A Family of Universal Models for Atoms</strong> <br />
  <em><small>Brandon M. Wood, Misko Dzamba, Xiang Fu, Meng Gao, Muhammed Shuaibi, Luis Barroso-Luque, Kareem Abdelmaqsoud, Vahe Gharakhanyan, John R. Kitchin, Daniel S. Levine, Kyle Michel, Anuroop Sriram, Taco Cohen, Abhishek Das, Ammar Rizvi, Sushree Jagriti Sahoo, Zachary W. Ulissi, C. Lawrence Zitnick </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2506.23971" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#wood2025Uma_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="wood2025Uma_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/fairchem" target="_blank"><button class="btn-common">CODE</button></a> 
  
  <a href="https://huggingface.co/facebook/UMA" target="_blank"><button class="btn-common">MODELS</button></a> 
  


<br/>
<div class="collapse" id="wood2025Uma_abs"><div class="well-abstract">
<small> <p align="justify"> The ability to quickly and accurately compute properties from atomic simulations is critical for advancing a large number of applications in chemistry and materials science including drug discovery, energy storage, and semiconductor manufacturing. To address this need, Meta FAIR presents a family of Universal Models for Atoms (UMA), designed to push the frontier of speed, accuracy, and generalization. UMA models are trained on half a billion unique 3D atomic structures (the largest training runs to date) by compiling data across multiple chemical domains, e.g. molecules, materials, and catalysts. We develop empirical scaling laws to help understand how to increase model capacity alongside dataset size to achieve the best accuracy. The UMA small and medium models utilize a novel architectural design we refer to as mixture of linear experts that enables increasing model capacity without sacrificing speed. For example, UMA-medium has 1.4B parameters but only ~50M active parameters per atomic structure. We evaluate UMA models on a diverse set of applications across multiple domains and find that, remarkably, a single model without any fine-tuning can perform similarly or better than specialized models. We are releasing the UMA code, weights, and associated data to accelerate computational workflows and enable the community to continue to build increasingly capable AI models. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/havens25AdjointSampling.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching</strong> <br />
  <em><small>Aaron Havens, Benjamin Kurt Miller, Bing Yan, Carles Domingo-Enrich, Anuroop Sriram, Brandon Wood, Daniel Levine, Bin Hu, Brandon Amos, Brian Karrer, Xiang Fu, Guan-Horng Liu, Ricky T. Q. Chen </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2504.11713" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#havens25AdjointSampling_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="havens25AdjointSampling_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/adjoint_sampling" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="havens25AdjointSampling_abs"><div class="well-abstract">
<small> <p align="justify"> We introduce Adjoint Sampling, a highly scalable and efficient algorithm for learning diffusion processes that sample from unnormalized densities, or energy functions. It is the first on-policy approach that allows significantly more gradient updates than the number of energy evaluations and model samples, allowing us to scale to much larger problem settings than previously explored by similar methods. Our framework is theoretically grounded in stochastic optimal control and shares the same theoretical guarantees as Adjoint Matching, being able to train without the need for corrective measures that push samples towards the target distribution. We show how to incorporate key symmetries, as well as periodic boundary conditions, for modeling molecules in both cartesian and torsional coordinates. We demonstrate the effectiveness of our approach through extensive experiments on classical energy functions, and further scale up to neural network-based energy models where we perform amortized conformer generation across many molecular systems. To encourage further research in developing highly scalable sampling methods, we plan to open source these challenging benchmarks, where successful methods can directly impact progress in computational chemistry. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/adit25.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> All-atom Diffusion Transformers: Unified generative modelling of molecules and materials</strong> <br />
  <em><small>Chaitanya K. Joshi, Xiang Fu, Yi-Lun Liao, Vahe Gharakhanyan, Benjamin Kurt Miller, Anuroop Sriram, Zachary W. Ulissi </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2503.03965" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#adit25_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="adit25_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/all-atom-diffusion-transformer" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="adit25_abs"><div class="well-abstract">
<small> <p align="justify"> Diffusion models are the standard toolkit for generative modelling of 3D atomic systems. However, for different types of atomic systems - such as molecules and materials - the generative processes are usually highly specific to the target system despite the underlying physics being the same. We introduce the All-atom Diffusion Transformer (ADiT), a unified latent diffusion framework for jointly generating both periodic materials and non-periodic molecular systems using the same model: (1) An autoencoder maps a unified, all-atom representations of molecules and materials to a shared latent embedding space; and (2) A diffusion model is trained to generate new latent embeddings that the autoencoder can decode to sample new molecules or materials. Experiments on QM9 and MP20 datasets demonstrate that jointly trained ADiT generates realistic and valid molecules as well as materials, exceeding state-of-the-art results from molecule and crystal-specific models. ADiT uses standard Transformers for both the autoencoder and diffusion model, resulting in significant speedups during training and inference compared to equivariant diffusion models. Scaling ADiT up to half a billion parameters predictably improves performance, representing a step towards broadly generalizable foundation models for generative chemistry. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
</li>
<li class="flex-item2">
  <strong> Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective</strong> <br />
  <em><small>Neta Shaul, Itai Gat, Marton Havasi, Daniel Severo, Anuroop Sriram, Peter Holderrieth, Brian Karrer, Yaron Lipman, Ricky T. Q. Chen </small></em><br />
  <small><b>International Conference on Learning Representations (ICLR) 2025</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2412.03487" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#shaulDFM24_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="shaulDFM24_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/flow_matching" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="shaulDFM24_abs"><div class="well-abstract">
<small> <p align="justify"> The design space of discrete-space diffusion or flow generative models are significantly less well-understood than their continuous-space counterparts, with many works focusing only on a simple masked construction. In this work, we aim to take a holistic approach to the construction of discrete generative models based on continuous-time Markov chains, and for the first time, allow the use of arbitrary discrete probability paths, or colloquially, corruption processes. Through the lens of optimizing the symmetric kinetic energy, we propose velocity formulas that can be applied to any given probability path, completely decoupling the probability and velocity, and giving the user the freedom to specify any desirable probability path based on expert knowledge specific to the data domain. Furthermore, we find that a special construction of mixture probability paths optimizes the symmetric kinetic energy for the discrete case. We empirically validate the usefulness of this new design space across multiple modalities: text generation, inorganic material generation, and image generation. We find that we can outperform the mask construction even in text with kinetic-optimal mixture paths, while we can make use of domain-specific constructions of the probability path over the visual domain. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2024</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/flowllm.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions</strong> <br />
  <em><small>Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M Wood </small></em><br />
  <small><b>NeurIPS 2024</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2410.23405" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramFlowllm24_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramFlowllm24_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/flowmm" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="sriramFlowllm24_abs"><div class="well-abstract">
<small> <p align="justify"> Material discovery is a critical area of research with the potential to revolutionize various fields, including carbon capture, renewable energy, and electronics. However, the immense scale of the chemical space makes it challenging to explore all possible materials experimentally. In this paper, we introduce FlowLLM, a novel generative model that combines large language models (LLMs) and Riemannian flow matching (RFM) to design novel crystalline materials. FlowLLM first fine-tunes an LLM to learn an effective base distribution of meta-stable crystals in a text representation. After converting to a graph representation, the RFM model takes samples from the LLM and iteratively refines the coordinates and lattice parameters. Our approach significantly outperforms state-of-the-art methods, increasing the generation rate of stable materials by over three times and increasing the rate for stable, unique, and novel crystals by ‚àº50% - a huge improvement on a difficult problem. Additionally, the crystals generated by FlowLLM are much closer to their relaxed state when compared with another leading model, significantly reducing post-hoc computational cost. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/flowmm24.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> FlowMM: Generating Materials with Riemannian Flow Matching</strong> <br />
  <em><small>Benjamin Kurt Miller, Ricky T. Q. Chen, Anuroop Sriram, Brandon M Wood </small></em><br />
  <small><b>International Conference on Machine Learning (ICML) 2024</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2402.04379" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#flowmm24_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="flowmm24_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/flowmm" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="flowmm24_abs"><div class="well-abstract">
<small> <p align="justify"> Crystalline materials are a fundamental component in next-generation technologies, yet modeling their distribution presents unique computational challenges. Of the plausible arrangements of atoms in a periodic lattice only a vanishingly small percentage are thermodynamically stable, which is a key indicator of the materials that can be experimentally realized. Two fundamental tasks in this area are to (a) predict the stable crystal structure of a known composition of elements and (b) propose novel compositions along with their stable structures. We present FlowMM, a pair of generative models that achieve state-of-the-art performance on both tasks while being more efficient and more flexible than competing methods. We extend Riemannian Flow Matching to suit the symmetries inherent to crystals: translation, rotation, permutation, and periodic boundary conditions. Our framework enables the freedom to choose the flow base distributions, drastically simplifying the problem of learning crystal structures compared with diffusion models. In addition to standard benchmarks, we validate FlowMM&#39;s generated structures with quantum chemistry calculations, demonstrating that it is 3x more efficient, in terms of integration steps, at finding stable materials compared to previous open methods. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/llm_materials23.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Fine-Tuned Language Models Generate Stable Inorganic Materials as Text</strong> <br />
  <em><small>Nate Gruver, Anuroop Sriram, Andrea Madotto, Andrew Wilson, C Lawrence Zitnick, Zachary Ulissi </small></em><br />
  <small><b>International Conference on Learning Representations (ICLR) 2024</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2402.04379" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#llm_materials23_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="llm_materials23_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/crystal-llm" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="llm_materials23_abs"><div class="well-abstract">
<small> <p align="justify"> Deep learning models have drastically accelerated materials discovery by accelerating predictive computational simulations like density functional theory (DFT). Large open computational materials databases such as the Materials Project or OQMD contain O(10&lt;sup&gt;6&lt;/sup&gt;) known structures, and it is now straightforward to search those databases for materials with exciting properties. However, these databases are limited to experimentally known materials or candidates discovered in high-throughput computational campaigns. Many state-of-the-art engineering advances in solar photovaltaics, battery electrodes, and catalysts are made by discovering materials with outstanding properties that have not yet been discovered. Generative models are a natural solution to expand families of interest through sampling. While popular methods are typically constructed from variational autoencoders or diffusion models, we propose fine-tuning large language models for generation of stable materials. While unorthodox, fine-tuning large language models on text-encoded atomistic data is simple to implement yet reliable, with around 90% of sampled structures obeying physical constraints on atom positions and charges. Using energy of hull calculations from both learned ML potentials and gold-standard DFT calculations, we show that our strongest model (fine-tuned LLaMA-2 70B) can generate materials predicted to be metastable at about twice the rate (49% vs 28%) of CDVAE, a competing diffusion model. Because of text prompting&#39;s inherent flexibility, our models can simultaneously be used for unconditional generation of stable material, infilling of partial structures and text-conditional generation. Finally, we show that language models&#39; ability to capture key symmetries of crystal structures improves with model scale, suggesting that the biases of pretrained LLMs are surprisingly well-suited for atomistic data. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/odac23.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> The Open DAC 2023 Dataset and Challenges for Sorbent Discovery in Direct Air Capture</strong> <br />
  <em><small>Anuroop Sriram, Sihoon Choi, Xiaohan Yu, Logan M. Brabson, Abhishek Das, Zachary Ulissi, Matt Uyttendaele, Andrew J. Medford, David S. Sholl </small></em><br />
  <small><b>ACS: Central Science</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2311.00341" target="_blank"><button class="btn-common">ARXIV</button></a> 
  <a href="https://pubs.acs.org/doi/10.1021/acscentsci.3c01629" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#odac23_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="odac23_abs">ABSTRACT</a>
  <a href="https://github.com/Open-Catalyst-Project/ocp/" target="_blank"><button class="btn-common">CODE</button></a> 
  <a href="https://github.com/Open-Catalyst-Project/ocp/blob/main/DATASET.md#odac23" target="_blank"><button class="btn-common">DATA</button></a> 
  
   <a data-toggle="collapse" href="#odac23_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="odac23_press">MEDIA</a>


<br/>
<div class="collapse" id="odac23_abs"><div class="well-abstract">
<small> <p align="justify"> New methods for carbon dioxide removal are urgently needed to combat global climate change. Direct air capture (DAC) is an emerging technology to capture carbon dioxide directly from ambient air. Metal-organic frameworks (MOFs) have been widely studied as potentially customizable adsorbents for DAC. However, discovering promising MOF sorbents for DAC is challenging because of the vast chemical space to explore and the need to understand materials as functions of humidity and temperature. We explore a computational approach benefiting from recent innovations in machine learning (ML) and present a dataset named Open DAC 2023 (ODAC23) consisting of more than 38M density functional theory (DFT) calculations on more than 8,800 MOF materials containing adsorbed CO&lt;sub&gt;2&lt;/sub&gt; and/or H&lt;sub&gt;2&lt;/sub&gt;O. ODAC23 is by far the largest dataset of MOF adsorption calculations at the DFT level of accuracy currently available. In addition to probing properties of adsorbed molecules, the dataset is a rich source of information on structural relaxation of MOFs, which will be useful in many contexts beyond specific applications for DAC. A large number of MOFs with promising properties for DAC are identified directly in ODAC23. We also trained state-of-the-art ML models on this dataset to approximate calculations at the DFT level. This open-source dataset and our initial ML models will provide an important baseline for future efforts to identify MOFs for a wide range of applications, including DAC. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="odac23_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://techcrunch.com/2024/05/04/this-week-in-ai-generative-ai-and-the-problem-of-compensating-creators/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/techcrunch.webp');"> 
      "This Week in AI: Generative AI and the problem of compensating creators"
       by Kyle Wiggers  Devin Coldewey
    </li>
    </a>
  
    <a href="https://techxplore.com/news/2024-05-massive-dataset-advance-ai-solutions.html" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/techxplore.webp');"> 
      "Researchers create massive open dataset to advance AI solutions for carbon capture"
       by Catherine Barzler
    </li>
    </a>
  
    <a href="https://carbonherald.com/meta-and-georgia-tech-released-open-direct-air-capture-dataset/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/carbonherald.webp');"> 
      "Meta And Georgia Tech Release Open Direct Air Capture Dataset To Accelerate Research"
       by Petya Trendafilova
    </li>
    </a>
  
    <a href="https://www.marktechpost.com/2023/11/09/meta-georgiatech-researchers-release-a-new-dataset-and-associated-ai-models-to-help-accelerate-research-on-direct-air-capture-to-combat-climate-change/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/mtp.webp');"> 
      "Meta &amp; Georgia Tech Researchers Release a New Dataset and Associated AI Models to Help Accelerate Research on Direct Air Capture to Combat Climate Change"
       by Rachit Ranjan
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/dac_nist24.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Integrating crystallographic and computational approaches to carbon-capture materials for the mitigation of climate change</strong> <br />
  <em><small>Eric Cockayne, Austin McDannald, Winnie Wong-Ng, Yu-Sheng Chen, Felipe G√°ndara, Jason Benedict, Christopher H Hendon, David A Keen, Ute Kolb, Lan Li, Shengqian Ma, William Morris, Aditya Nandy, Tomƒçe Runƒçevski, Mustapha Soukri, Anuroop Sriram, Janice A Steckel, John Findley, Christopher Eli Wilmer, Taner Yildirim, Wei Zhou, Igor Levin, Craig M Brown </small></em><br />
  <small><b>Journal of Materials Chemistry A</b></small> 
  <br/>

  
  
  <a href="https://pubs.rsc.org/en/content/articlelanding/2024/ta/d4ta04136d" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#dac_nist24_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="dac_nist24_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="dac_nist24_abs"><div class="well-abstract">
<small> <p align="justify"> This article presents an overview of the current state of the art in the structure determination of microporous carbon-capture materials, as discussed at the recent NIST workshop &#34;Integrating Crystallographic and Computational Approaches to Carbon-Capture Materials for the Mitigation of Climate Change&#34;. The continual rise in anthropogenic CO2 concentration and its effect on climate change call for the implementation of carbon capture technologies to reduce the CO2 concentration in the atmosphere. Porous solids, including metal‚Äìorganic frameworks (MOFs), are feasible candidates for gas capture and storage applications. However, determining the structure of these materials represents a significant obstacle in their development into advanced sorbents. The existing difficulties can be overcome by integrating crystallographic methods and theoretical modeling. The workshop gathered experimentalists and theorists from academia, government, and industry to review this field and identify approaches, including collaborative opportunities, required to develop tools for rapid determination of the structures of porous solid sorbents and the effect of structure on the carbon capture performance. We highlight the findings of that workshop, especially in the need for reference materials, standardized procedures and reporting of sorbent activation and adsorption measurements, standardized reporting of theoretical calculations, and round-robin structure determination. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/molreg24.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Distribution Learning for Molecular Regression</strong> <br />
  <em><small>Nima Shoghi, Pooya Shoghi, Anuroop Sriram, Abhishek Das </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2407.20475" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#molreg24_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="molreg24_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="molreg24_abs"><div class="well-abstract">
<small> <p align="justify"> Using &#34;soft&#34; targets to improve model performance has been shown to be effective in classification settings, but the usage of soft targets for regression is a much less studied topic in machine learning. The existing literature on the usage of soft targets for regression fails to properly assess the method&#39;s limitations, and empirical evaluation is quite limited. In this work, we assess the strengths and drawbacks of existing methods when applied to molecular property regression tasks. Our assessment outlines key biases present in existing methods and proposes methods to address them, evaluated through careful ablation studies. We leverage these insights to propose Distributional Mixture of Experts (DMoE): A model-independent, and data-independent method for regression which trains a model to predict probability distributions of its targets. Our proposed loss function combines the cross entropy between predicted and target distributions and the L1 distance between their expected values to produce a loss function that is robust to the outlined biases. We evaluate the performance of DMoE on different molecular property prediction datasets -- Open Catalyst (OC20), MD17, and QM9 -- across different backbone model architectures -- SchNet, GemNet, and Graphormer. Our results demonstrate that the proposed method is a promising alternative to classical regression for molecular property prediction tasks, showing improvements over baselines on all datasets and architectures. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2023</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/tranOC22.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> The Open Catalyst 2022 (OC22) Dataset and Challenges for Oxide Electrocatalysis</strong> <br />
  <em><small>Richard Tran, Janice Lan, Muhammed Shuaibi, Siddharth Goyal, Brandon M Wood, Abhishek Das, Javier Heras-Domingo, Adeesh Kolluru, Ammar Rizvi, Nima Shoghi et al. </small></em><br />
  <small><b>ACS Catalysis</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2206.08917" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#tranOc22_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="tranOc22_abs">ABSTRACT</a>
  <a href="https://github.com/open-catalyst-project/ocp" target="_blank"><button class="btn-common">CODE</button></a> 
  <a href="https://github.com/Open-Catalyst-Project/ocp/blob/main/DATASET.md#open-catalyst-2022-oc22" target="_blank"><button class="btn-common">DATA</button></a> 
  
   <a data-toggle="collapse" href="#tranOc22_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="tranOc22_press">MEDIA</a>


<br/>
<div class="collapse" id="tranOc22_abs"><div class="well-abstract">
<small> <p align="justify"> Computational catalysis and machine learning communities have made considerable progress in developing machine learning models for catalyst discovery and design. Yet, a general machine learning potential that spans the chemical space of catalysis is still out of reach. A significant hurdle is obtaining access to training data across a wide range of materials. One important class of materials where data is lacking are oxides, which inhibits models from studying the Oxygen Evolution Reaction and oxide electrocatalysis more generally. To address this we developed the Open Catalyst 2022(OC22) dataset, consisting of 62,521 Density Functional Theory (DFT) relaxations (~9,884,504 single point calculations) across a range of oxide materials, coverages, and adsorbates (*H, *O, *N, *C, *OOH, *OH, *OH2, *O2, *CO). We define generalized tasks to predict the total system energy that are applicable across catalysis, develop baseline performance of several graph neural networks (SchNet, DimeNet++, ForceNet, SpinConv, PaiNN, GemNet-dT, GemNet-OC), and provide pre-defined dataset splits to establish clear benchmarks for future efforts. For all tasks, we study whether combining datasets leads to better results, even if they contain different materials or adsorbates. Specifically, we jointly train models on Open Catalyst 2020 (OC20) Dataset and OC22, or fine-tune pretrained OC20 models on OC22. In the most general task, GemNet-OC sees a ~32% improvement in energy predictions through fine-tuning and a ~9% improvement in force predictions via joint training. Surprisingly, joint training on both the OC20 and much smaller OC22 datasets also improves total energy predictions on OC20 by ~19%. The dataset and baseline models are open sourced, and a public leaderboard will follow to encourage continued community developments on the total energy tasks and data. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="tranOc22_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://ai.facebook.com/blog/accelerating-renewable-energy-with-a-new-data-set-for-green-hydrogen-fuel/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/fair.webp');"> 
      "Accelerating renewable energy with new dataset for green hydrogen fuel"
       by Janice Lan, Siddharth Goyal, Ammar Rizvi, Larry Zitnick
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/cf.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Cold fusing sequence-to-sequence models with language models (Patent)</strong> <br />
  <em><small>Anuroop Sriram, Heewoo Jun, Sanjeev Satheesh, Adam Coates </small></em><br />
  <small><b>US Patent 11,620,986</b></small> 
  <br/>

  
  
  
  
  <a href="https://patentimages.storage.googleapis.com/7f/5e/0e/dd03b5f5b8b226/US11620986.pdf" target="_blank"><button class="btn-common">PATENT</button></a> 
   <a data-toggle="collapse" href="#_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="_abs"><div class="well-abstract">
<small> <p align="justify"> Described herein are systems and methods for generating natural language sentences with Sequence-to-sequence (Seq2Seq) models with attention. The Seq2Seq models may be implemented in applications, such as machine translation, image captioning, and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language models. Disclosed herein are ‚ÄúCold Fusion‚Äù architecture embodiments that leverage a pre-trained language model during training. The Seq2Seq models with Cold Fusion embodiments are able to better utilize language information enjoying faster convergence, better generalization, and almost complete transfer to a new domain while using less labeled training data. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/mri_prosp.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Deep Learning Reconstruction Enables Prospectively Accelerated Clinical Knee MRI</strong> <br />
  <em><small>Patricia M. Johnson, Dana J. Lin, Jure Zbontar, C. Lawrence Zitnick, Anuroop Sriram, Matthew Muckley, James S. Babb, Mitchell Kline, Gina Ciavarra, Erin Alaia, Mohammad Samim, William R. Walter, Liz Calderon, Thomas Pock, Daniel K. Sodickson, Michael P. Recht, and Florian Knoll </small></em><br />
  <small><b>Radiology</b></small> 
  <br/>

  
  
  <a href="https://pubs.rsna.org/doi/10.1148/radiol.220425" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#johnsonMRIProsp_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="johnsonMRIProsp_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/fastMRI/tree/main/fastmri_examples/RadiologyJohnson2022" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
   <a data-toggle="collapse" href="#johnsonMRIProsp_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="johnsonMRIProsp_press">MEDIA</a>


<br/>
<div class="collapse" id="johnsonMRIProsp_abs"><div class="well-abstract">
<small> <p align="justify"> Compared with conventional reconstruction, deep learning reconstruction of prospectively accelerated knee MRI enabled an almost two fold scan time reduction, improved image quality, and had equivalent diagnostic utility.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Background&lt;/b&gt;&lt;br/&gt;MRI is a powerful diagnostic tool with a long acquisition time. Recently, deep learning (DL) methods have provided accelerated high-quality image reconstructions from undersampled data, but it is unclear if DL image reconstruction can be reliably translated to everyday clinical practice.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Purpose&lt;/b&gt;&lt;br/&gt;To determine the diagnostic equivalence of prospectively accelerated DL-reconstructed knee MRI compared with conventional accelerated MRI for evaluating internal derangement of the knee in a clinical setting.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Materials and Methods&lt;/b&gt;&lt;br/&gt;A DL reconstruction model was trained with images from 298 clinical 3-T knee examinations. In a prospective analysis, patients clinically referred for knee MRI underwent a conventional accelerated knee MRI protocol at 3 T followed by an accelerated DL protocol between January 2020 and February 2021. The equivalence of the DL reconstruction of the images relative to the conventional images for the detection of an abnormality was assessed in terms of interchangeability. Each examination was reviewed by six musculoskeletal radiologists. Analyses pertaining to the detection of meniscal or ligament tears and bone marrow or cartilage abnormalities were based on four-point ordinal scores for the likelihood of an abnormality. Additionally, the protocols were compared with use of four-point ordinal scores for each aspect of image quality: overall image quality, presence of artifacts, sharpness, and signal-to-noise ratio.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Results&lt;/b&gt;&lt;br/&gt;A total of 170 participants (mean age ¬± SD, 45 years ¬± 16; 76 men) were evaluated. The DL-reconstructed images were determined to be of diagnostic equivalence with the conventional images for detection of abnormalities. The overall image quality score, averaged over six readers, was significantly better (P &lt; .001) for the DL than for the conventional images.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Conclusion&lt;/b&gt;&lt;br/&gt;In a clinical setting, deep learning reconstruction enabled a nearly twofold reduction in scan time for a knee MRI and was diagnostically equivalent with the conventional protocol. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="johnsonMRIProsp_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://www.youtube.com/watch?v=9ncABdfkzuU" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/cbs.webp');"> 
      "Breakthrough MRI technology uses AI for faster scans"
      
    </li>
    </a>
  
    <a href="https://pubs.rsna.org/doi/full/10.1148/radiol.222872" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/radiology.webp');"> 
      "Editorial: The Role of Speed and Possible Implications"
       by Frank Roemer
    </li>
    </a>
  
    <a href="https://nyulangone.org/news/artificial-intelligence-reconstructs-missing-data-rapid-mri-scans" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/nyu_langone.webp');"> 
      "Artificial Intelligence Reconstructs Missing Data from Rapid MRI Scans"
      
    </li>
    </a>
  
    <a href="https://www.reuters.com/article/health-rounds/health-rounds-ai-speeds-mri-exams-idINL1N3421K1" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/reuters.webp');"> 
      "Health Rounds: AI speeds MRI exams"
      
    </li>
    </a>
  
    <a href="https://medicalxpress.com/news/2023-01-deep-reconstruction-enables-knee-mri.html" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/medxpress.webp');"> 
      "Deep learning reconstruction enables accelerated knee MRI"
       by Elana Gotkine
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2022</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/mri_limits.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Exploring the Acceleration Limits of Deep Learning VarNet-based Two-dimensional Brain MRI</strong> <br />
  <em><small>Alireza Radmanesh, Matthew J. Muckley , Tullie Murrell, Emma Lindsey, Anuroop Sriram, Florian Knoll, Daniel K. Sodickson, Yvonne W. Lui </small></em><br />
  <small><b>Radiology: Artificial Intelligence</b></small> 
  <br/>

  
  
  <a href="https://pubs.rsna.org/doi/10.1148/ryai.210313" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#radmaneshMRIAccel_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="radmaneshMRIAccel_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/fastMRI/" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="radmaneshMRIAccel_abs"><div class="well-abstract">
<small> <p align="justify"> &lt;b&gt;Purpose:&lt;/b&gt;&lt;br/&gt;To explore the limits of deep learning-based brain MRI reconstruction and identify useful acceleration ranges for general-purpose imaging and potential screening.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Materials and Methods:&lt;/b&gt;&lt;br/&gt;In this retrospective study conducted from 2019 through 2021, a model was trained for reconstruction on 5,847 brain MRIs. Performance was evaluated across a wide range of accelerations (up to 100-fold along a single phase-encoded direction for two-dimensional [2D] slices) on the fastMRI test set collected by New York University, consisting of 558 image volumes. In a sample of 69 volumes, reconstructions were classified by radiologists for identifying two clinical thresholds: 1) general-purpose diagnostic imaging and 2) potential use in a screening protocol. A Monte Carlo procedure was developed for estimating reconstruction error with only undersampled data. The model was evaluated on both in-domain and out-of-domain data. Confidence intervals were calculated using the percentile bootstrap method.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Results:&lt;/b&gt;&lt;br/&gt;Radiologists rated 100% of 69 volumes as having sufficient image quality for general-purpose imaging at up to 4√ó acceleration and 65 of 69 (94%) of volumes as having sufficient image quality for screening at up to 14√ó acceleration. The Monte Carlo procedure estimated ground truth peak signal-to-noise ratio and mean squared error with coefficients of determination greater than 0.5 at all accelerations. Out-of-distribution experiments demonstrated the model‚Äôs ability to produce images substantially distinct from the training set, even at 100√ó acceleration.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Conclusion:&lt;/b&gt;&lt;br/&gt;For 2D brain images using deep learning-based reconstruction, maximum acceleration for potential screening was 3‚Äì4 times higher than that for diagnostic general-purpose imaging. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/ocp_chall.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> The Open Catalyst Challenge 2021: Competition Report</strong> <br />
  <em><small>Abhishek Das, Muhammed Shuaibi, Aini Palizhati, Siddharth Goyal, Aditya Grover, Adeesh Kolluru, Janice Lan, Ammar Rizvi, Anuroop Sriram, Brandon Wood et al. </small></em><br />
  <small><b>NeurIPS 2021 Competitions and Demonstrations Track</b></small> 
  <br/>

  
  
  <a href="https://proceedings.mlr.press/v176/das22a.html" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#dasOC21_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="dasOC21_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="dasOC21_abs"><div class="well-abstract">
<small> <p align="justify"> In this report, we describe the Open Catalyst Challenge held at NeurIPS 2021, focusing on using machine learning (ML) to accelerate the search for low-cost catalysts that can drive reactions converting renewable energy to storable forms. Specifically, the challenge required participants to develop ML approaches for relaxed energy prediction, i.e. given atomic positions for an adsorbate-catalyst system, the goal was to predict the energy of the system‚Äôs relaxed or lowest energy state. To perform well on this task, ML approaches need to approximate the quantum mechanical computations in Density Functional Theory (DFT). By modeling these accurately, the catalyst‚Äôs impact on the overall rate of a chemical reaction may be estimated; a key factor in filtering potential electrocatalyst materials. The challenge encouraged community-wide progress on this task and the winning approach improved direct relaxed energy prediction by  15% relative over the previous state-of-the-art. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/scn.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Spherical Channels for Modeling Atomic Interactions</strong> <br />
  <em><small>C Lawrence Zitnick, Abhishek Das, Adeesh Kolluru, Janice Lan, Muhammed Shuaibi, Anuroop Sriram, Zachary Ulissi, Brandon Wood </small></em><br />
  <small><b>NeurIPS 2022</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2206.14331" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#zitnickSphericalChannels_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="zitnickSphericalChannels_abs">ABSTRACT</a>
  <a href="https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/scn" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="zitnickSphericalChannels_abs"><div class="well-abstract">
<small> <p align="justify"> Modeling the energy and forces of atomic systems is a fundamental problem in computational chemistry with the potential to help address many of the world&#39;s most pressing problems, including those related to energy scarcity and climate change. These calculations are traditionally performed using Density Functional Theory, which is computationally very expensive. Machine learning has the potential to dramatically improve the efficiency of these calculations from days or hours to seconds. We propose the Spherical Channel Network (SCN) to model atomic energies and forces. The SCN is a graph neural network where nodes represent atoms and edges their neighboring atoms. The atom embeddings are a set of spherical functions, called spherical channels, represented using spherical harmonics. We demonstrate, that by rotating the embeddings based on the 3D edge orientation, more information may be utilized while maintaining the rotational equivariance of the messages. While equivariance is a desirable property, we find that by relaxing this constraint in both message passing and aggregation, improved accuracy may be achieved. We demonstrate state-of-the-art results on the large-scale Open Catalyst 2020 dataset in both energy and force prediction for numerous tasks and metrics. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/w2vaug.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Wav2Vec-Aug: Improved self-supervised training with limited data</strong> <br />
  <em><small>Anuroop Sriram, Michael Auli, Alexei Baevski </small></em><br />
  <small><b>Interspeech 2022</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2206.13654" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramWav2vecaug_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramWav2vecaug_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="sriramWav2vecaug_abs"><div class="well-abstract">
<small> <p align="justify"> Self-supervised learning (SSL) of speech representations has received much attention over the last few years but most work has focused on languages and domains with an abundance of unlabeled data. However, for many languages there is a shortage even in the unlabeled data which limits the effectiveness of SSL. In this work, we focus on the problem of applying SSL to domains with limited available data by leveraging data augmentation for Wav2Vec 2.0 pretraining. Further, we propose improvements to each component of the model which result in a combined relative word error rate (WER) improvement of up to 13% compared to Wav2Vec 2.0 on Librispeech test-clean / other. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/gemnetoc.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> GemNet-OC: Developing Graph Neural Networks for Large and Diverse Molecular Simulation Datasets</strong> <br />
  <em><small>Johannes Gasteiger, Muhammed Shuaibi, Anuroop Sriram, Stephan Gunnemann, Zachary Ulissi, C Lawrence Zitnick, Abhishek Das </small></em><br />
  <small><b>Transactions on Machine Learning Research (TMLR) 2022</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2204.02782" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#gasteigerGemnetOC_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="gasteigerGemnetOC_abs">ABSTRACT</a>
  <a href="https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/gemnet_oc" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="gasteigerGemnetOC_abs"><div class="well-abstract">
<small> <p align="justify"> Recent years have seen the advent of molecular simulation datasets that are orders of magnitude larger and more diverse. These new datasets differ substantially in four aspects of complexity: 1. Chemical diversity (number of different elements), 2. system size (number of atoms per sample), 3. dataset size (number of data samples), and 4. domain shift (similarity of the training and test set). Despite these large differences, benchmarks on small and narrow datasets remain the predominant method of demonstrating progress in graph neural networks (GNNs) for molecular simulation, likely due to cheaper training compute requirements. This raises the question -- &lt;em&gt;does GNN progress on small and narrow datasets translate to these more complex datasets?&lt;/em&gt; This work investigates this question by first developing the GemNet-OC model based on the large Open Catalyst 2020 (OC20) dataset. GemNet-OC outperforms the previous state-of-the-art on OC20 by 16% while reducing training time by a factor of 10. We then compare the impact of 18 model components and hyperparameter choices on performance in multiple datasets. We find that the resulting model would be drastically different depending on the dataset used for making model choices. To isolate the source of this discrepancy we study six subsets of the OC20 dataset that individually test each of the above-mentioned four dataset aspects. We find that results on the OC-2M subset correlate well with the full OC20 dataset while being substantially cheaper to train on. Our findings challenge the common practice of developing GNNs solely on small datasets, but highlight ways of achieving fast development cycles and generalizable results via moderately-sized, representative datasets such as OC-2M and efficient models such as GemNet-OC. Our code and pretrained model weights are open-sourced. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/graph_parallel.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations</strong> <br />
  <em><small>Anuroop Sriram, Abhishek Das, Brandon M Wood, Siddharth Goyal, C Lawrence Zitnick </small></em><br />
  <small><b>International Conference on Learning Representations (ICLR) 2022</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2203.09697" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramGraphParallel_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramGraphParallel_abs">ABSTRACT</a>
  <a href="https://github.com/Open-Catalyst-Project/ocp/tree/main/ocpmodels/models/gemnet_gp" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="sriramGraphParallel_abs"><div class="well-abstract">
<small> <p align="justify"> Recent progress in Graph Neural Networks (GNNs) for modeling atomic simulations has the potential to revolutionize catalyst discovery, which is a key step in making progress towards the energy breakthroughs needed to combat climate change. However, the GNNs that have proven most effective for this task are memory intensive as they model higher-order interactions in the graphs such as those between triplets or quadruplets of atoms, making it challenging to scale these models. In this paper, we introduce &lt;em&gt;Graph Parallelism&lt;/em&gt;, a method to distribute input graphs across multiple GPUs, enabling us to train very large GNNs with hundreds of millions or billions of parameters. We empirically evaluate our method by scaling up the number of parameters of the recently proposed DimeNet++ and GemNet models by over an order of magnitude. On the large-scale Open Catalyst 2020 (OC20) dataset, these graph-parallelized models lead to relative improvements of 1) 15% on the force MAE metric for the S2EF task and 2) 21% on the AFbT metric for the IS2RS task, establishing new state-of-the-art results&lt;/em&gt;. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2021</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/spinconv.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Rotation invariant graph neural networks using spin convolutions</strong> <br />
  <em><small>Muhammed Shuaibi, Adeesh Kolluru, Abhishek Das, Aditya Grover, Anuroop Sriram, Zachary Ulissi, C Lawrence Zitnick </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2106.09575" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#shuaibiSpinconv_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="shuaibiSpinconv_abs">ABSTRACT</a>
  <a href="https://github.com/Open-Catalyst-Project/ocp" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="shuaibiSpinconv_abs"><div class="well-abstract">
<small> <p align="justify"> Progress towards the energy breakthroughs needed to combat climate change can be significantly accelerated through the efficient simulation of atomic systems. Simulation techniques based on first principles, such as Density Functional Theory (DFT), are limited in their practical use due to their high computational expense. Machine learning approaches have the potential to approximate DFT in a computationally efficient manner, which could dramatically increase the impact of computational simulations on real-world problems. Approximating DFT poses several challenges. These include accurately modeling the subtle changes in the relative positions and angles between atoms, and enforcing constraints such as rotation invariance or energy conservation. We introduce a novel approach to modeling angular information between sets of neighboring atoms in a graph neural network. Rotation invariance is achieved for the network&#39;s edge messages through the use of a per-edge local coordinate frame and a novel spin convolution over the remaining degree of freedom. Two model variants are proposed for the applications of structure relaxation and molecular dynamics. State-of-the-art results are demonstrated on the large-scale Open Catalyst 2020 dataset. Comparisons are also performed on the MD17 and QM9 datasets. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/oc20.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Open catalyst 2020 (OC20) dataset and community challenges</strong> <br />
  <em><small>Lowik Chanussot, Abhishek Das, Siddharth Goyal, Thibaut Lavril, Muhammed Shuaibi, Morgane Riviere, Kevin Tran, Javier Heras-Domingo, Caleb Ho, Weihua Hu et al. </small></em><br />
  <small><b>ACS Catalysis</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2010.09990" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#chanussotOC20_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="chanussotOC20_abs">ABSTRACT</a>
  <a href="https://github.com/open-catalyst-project/ocp" target="_blank"><button class="btn-common">CODE</button></a> 
  <a href="https://github.com/Open-Catalyst-Project/ocp/blob/main/DATASET.md" target="_blank"><button class="btn-common">DATA</button></a> 
  
   <a data-toggle="collapse" href="#chanussotOC20_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="chanussotOC20_press">MEDIA</a>


<br/>
<div class="collapse" id="chanussotOC20_abs"><div class="well-abstract">
<small> <p align="justify"> Catalyst discovery and optimization is key to solving many societal and energy challenges including solar fuels synthesis, long-term energy storage, and renewable fertilizer production. Despite considerable effort by the catalysis community to apply machine learning models to the computational catalyst discovery process, it remains an open challenge to build models that can generalize across both elemental compositions of surfaces and adsorbate identity/configurations, perhaps because datasets have been smaller in catalysis than related fields. To address this we developed the OC20 dataset, consisting of 1,281,040 Density Functional Theory (DFT) relaxations (~264,890,000 single point evaluations) across a wide swath of materials, surfaces, and adsorbates (nitrogen, carbon, and oxygen chemistries). We supplemented this dataset with randomly perturbed structures, short timescale molecular dynamics, and electronic structure analyses. The dataset comprises three central tasks indicative of day-to-day catalyst modeling and comes with pre-defined train/validation/test splits to facilitate direct comparisons with future model development efforts. We applied three state-of-the-art graph neural network models (CGCNN, SchNet, Dimenet++) to each of these tasks as baseline demonstrations for the community to build on. In almost every task, no upper limit on model size was identified, suggesting that even larger models are likely to improve on initial results. The dataset and baseline models are both provided as open resources, as well as a public leader board to encourage community contributions to solve these important tasks. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="chanussotOC20_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://ai.facebook.com/blog/facebook-and-carnegie-mellon-launch-the-open-catalyst-project-to-find-new-ways-to-store-renewable-energy/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/fair.webp');"> 
      "Facebook and Carnegie Mellon launch the Open Catalyst Project to find new ways to store renewable energy"
       by Larry Zitnick
    </li>
    </a>
  
    <a href="https://fortune.com/2020/10/14/facebook-ai-open-catalyst-dataset-chemistry-renewable-energy/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/fortune.webp');"> 
      "Facebook A.I. researchers push for a breakthrough in renewable energy storage"
       by Jeremy Kahn
    </li>
    </a>
  
    <a href="https://www.engadget.com/facebook-deploys-its-ai-to-find-green-energy-storage-solutions-130041147.html" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/engadget.webp');"> 
      "Facebook deploys its AI to find green energy storage solutions"
       by Andrew Tarantola
    </li>
    </a>
  
    <a href="https://www.cnbc.com/2020/10/14/facebook-to-use-ai-in-bid-to-improve-renewable-energy-storage.html" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/cnbc.webp');"> 
      "Facebook to use artificial intelligence in bid to improve renewable energy storage"
       by Sam Shead
    </li>
    </a>
  
    <a href="https://venturebeat.com/ai/facebook-and-carnegie-mellon-launch-project-to-discover-better-ways-to-store-renewable-energy/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/venturebeat.webp');"> 
      "Facebook and Carnegie Mellon launch project to discover better ways to store renewable energy"
       by Kyle Wiggers
    </li>
    </a>
  
    <a href="https://www.cnet.com/science/facebook-plans-to-use-ai-to-help-fight-climate-change/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/cnet.webp');"> 
      "Facebook plans to use AI to help fight climate change"
       by Queenie Wong
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/fmri_chall2020.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Results of the 2020 fastmri challenge for machine learning mr image reconstruction</strong> <br />
  <em><small>Matthew J Muckley, Bruno Riemenschneider, Alireza Radmanesh, Sunwoo Kim, Geunu Jeong, Jingyu Ko, Yohan Jun, Hyungseob Shin, Dosik Hwang, Mahmoud Mostapha et al. </small></em><br />
  <small><b>IEEE Transactions on Medical Imaging (TMI)</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2012.06318" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#muckleyFastmri2020_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="muckleyFastmri2020_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="muckleyFastmri2020_abs"><div class="well-abstract">
<small> <p align="justify"> Accelerating MRI scans is one of the principal outstanding problems in the MRI research community. Towards this goal, we hosted the second fastMRI competition targeted towards reconstructing MR images with subsampled k-space data. We provided participants with data from 7,299 clinical brain scans (de-identified via a HIPAA-compliant procedure by NYU Langone Health), holding back the fully-sampled data from 894 of these scans for challenge evaluation purposes. In contrast to the 2019 challenge, we focused our radiologist evaluations on pathological assessment in brain images. We also debuted a new Transfer track that required participants to submit models evaluated on MRI scanners from outside the training set. We received 19 submissions from eight different groups. Results showed one team scoring best in both SSIM scores and qualitative radiologist evaluations. We also performed analysis on alternative metrics to mitigate the effects of background noise and collected feedback from the participants to inform future challenges. Lastly, we identify common failure modes across the submissions, highlighting areas of need for future research in the MRI reconstruction community. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/rsgan.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Systems and methods for robust speech recognition using generative adversarial networks (Patent)</strong> <br />
  <em><small>Anuroop Sriram, Hee Woo Jun, Yashesh Gaur, Sanjeev Satheesh </small></em><br />
  <small><b>US Patent 10,971,142</b></small> 
  <br/>

  
  
  
  
  <a href="https://patentimages.storage.googleapis.com/44/e8/47/bdbcfadc027d9c/US10971142.pdf" target="_blank"><button class="btn-common">PATENT</button></a> 
   <a data-toggle="collapse" href="#_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="_abs"><div class="well-abstract">
<small> <p align="justify"> Described herein are systems and methods for a general, scalable, end-to-end framework that uses a generative adversarial network (GAN) objective to enable robust speech recognition. Encoders trained with the proposed approach enjoy improved invariance by learning to map noisy audio to the same embedding space as that of clean audio. Embodiments of a Wasserstein GAN framework increase the robustness of seq-to-seq models in a scalable, end-to-end fashion. In one or more embodiments, an encoder component is treated as the generator of GAN and is trained to produce indistinguishable embeddings between labeled and unlabeled audio samples. This new robust training approach can learn to induce robustness without alignment or complicated inference pipeline and even where augmentation of audio data is not possible. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/w2vaug.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Robust Wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training</strong> <br />
  <em><small>Wei-Ning Hsu, Anuroop Sriram, Alexei Baevski, Tatiana Likhomanenko, Qiantong Xu, Vineel Pratap, Jacob Kahn, Ann Lee, Ronan Collobert, Gabriel Synnaeve, Michael Auli </small></em><br />
  <small><b>Interspeech 2021</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2104.01027" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#hsuRobustWav2Vec_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="hsuRobustWav2Vec_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="hsuRobustWav2Vec_abs"><div class="well-abstract">
<small> <p align="justify"> Self-supervised learning of speech representations has been a very active research area but most work is focused on a single domain such as read audio books for which there exist large quantities of labeled and unlabeled data. In this paper, we explore more general setups where the domain of the unlabeled data for pre-training data differs from the domain of the labeled data for fine-tuning, which in turn may differ from the test data domain. Our experiments show that using target domain data during pre-training leads to large performance improvements across a variety of setups. On a large-scale competitive setup, we show that pre-training on unlabeled in-domain data reduces the gap between models trained on in-domain and out-of-domain labeled data by 66%-73%. This has obvious practical implications since it is much easier to obtain unlabeled target domain data than labeled data. Moreover, we find that pre-training on multiple domains improves generalization performance on domains not seen during training. Code and models will be made available at this https URL. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/forcenet.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Forcenet: A graph neural network for large-scale quantum calculations</strong> <br />
  <em><small>Weihua Hu, Muhammed Shuaibi, Abhishek Das, Siddharth Goyal, Anuroop Sriram, Jure Leskovec, Devi Parikh, C Lawrence Zitnick </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2103.01436" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#huForcenet_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="huForcenet_abs">ABSTRACT</a>
  <a href="https://github.com/Open-Catalyst-Project/ocp/blob/main/ocpmodels/models/forcenet.py" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="huForcenet_abs"><div class="well-abstract">
<small> <p align="justify"> With massive amounts of atomic simulation data available, there is a huge opportunity to develop fast and accurate machine learning models to approximate expensive physics-based calculations. The key quantity to estimate is atomic forces, where the state-of-the-art Graph Neural Networks (GNNs) explicitly enforce basic physical constraints such as rotation-covariance. However, to strictly satisfy the physical constraints, existing models have to make tradeoffs between computational efficiency and model expressiveness. Here we explore an alternative approach. By not imposing explicit physical constraints, we can flexibly design expressive models while maintaining their computational efficiency. Physical constraints are implicitly imposed by training the models using physics-based data augmentation. To evaluate the approach, we carefully design a scalable and expressive GNN model, ForceNet, and apply it to OC20 (Chanussot et al., 2020), an unprecedentedly-large dataset of quantum physics calculations. Our proposed ForceNet is able to predict atomic forces more accurately than state-of-the-art physics-based GNNs while being faster both in training and inference. Overall, our promising and counter-intuitive results open up an exciting avenue for future research. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/covid19.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Covid-19 prognosis via self-supervised representation learning and multi-image prediction</strong> <br />
  <em><small>Anuroop Sriram, Matthew Muckley, Koustuv Sinha, Farah Shamout, Joelle Pineau, Krzysztof J Geras, Lea Azour, Yindalon Aphinyanaphongs, Nafissa Yakubova, William Moore </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2101.04909" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramCovid_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramCovid_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/CovidPrognosis" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
   <a data-toggle="collapse" href="#sriramCovid_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramCovid_press">MEDIA</a>


<br/>
<div class="collapse" id="sriramCovid_abs"><div class="well-abstract">
<small> <p align="justify"> The rapid spread of COVID-19 cases in recent months has strained hospital resources, making rapid and accurate triage of patients presenting to emergency departments a necessity. Machine learning techniques using clinical data such as chest X-rays have been used to predict which patients are most at risk of deterioration. We consider the task of predicting two types of patient deterioration based on chest X-rays: adverse event deterioration (i.e., transfer to the intensive care unit, intubation, or mortality) and increased oxygen requirements beyond 6 L per day. Due to the relative scarcity of COVID-19 patient data, existing solutions leverage supervised pretraining on related non-COVID images, but this is limited by the differences between the pretraining data and the target COVID-19 patient data. In this paper, we use self-supervised learning based on the momentum contrast (MoCo) method in the pretraining phase to learn more general image representations to use for downstream tasks. We present three results. The first is deterioration prediction from a single image, where our model achieves an area under receiver operating characteristic curve (AUC) of 0.742 for predicting an adverse event within 96 hours (compared to 0.703 with supervised pretraining) and an AUC of 0.765 for predicting oxygen requirements greater than 6 L a day at 24 hours (compared to 0.749 with supervised pretraining). We then propose a new transformer-based architecture that can process sequences of multiple images for prediction and show that this model can achieve an improved AUC of 0.786 for predicting an adverse event at 96 hours and an AUC of 0.848 for predicting mortalities at 96 hours. A small pilot clinical study suggested that the prediction accuracy of our model is comparable to that of experienced radiologists analyzing the same information. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="sriramCovid_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://www.cnet.com/health/facebook-uses-ai-to-predict-if-covid-19-patients-will-need-more-care/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/cnet.webp');"> 
      "Facebook uses AI to predict if COVID-19 patients will need more care"
       by Queenie Wong
    </li>
    </a>
  
    <a href="https://www.cnbc.com/2021/01/15/facebook-develops-ai-to-predict-likelihood-of-worsening-covid-symptoms.html" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/cnbc.webp');"> 
      "Facebook develops A.I. to predict likelihood of worsening Covid symptoms"
       by Sam Shead
    </li>
    </a>
  
    <a href="https://www.dailymail.co.uk/sciencetech/article-9153415/Facebook-claims-AI-predict-four-coronavirus-patients-condition-deteriorate.html" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/dailymail.webp');"> 
      "Facebook claims its AI can predict four days in advance if a coronavirus patient&#39;s condition will deteriorate - just by looking at a single chest X-ray"
       by Stacy Liberatore
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2020</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/fmri_chall2020.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> State-of-the-art machine learning MRI reconstruction in 2020: Results of the second fastMRI challenge</strong> <br />
  <em><small>Matthew Muckley, Bruno Riemenschneider, Alireza Radmanesh, Sunwoo Kim, Geunu Jeong, Jingyu Ko, Yohan Jun, Hyungseob Shin, Dosik Hwang, Mahmoud Mostapha et al. </small></em><br />
  <small><b></b></small> 
  <br/>

  
  
  <a href="https://hal.archives-ouvertes.fr/hal-03066150v1/document" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#muckeyFastMRI2020_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="muckeyFastMRI2020_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="muckeyFastMRI2020_abs"><div class="well-abstract">
<small> <p align="justify"> Accelerating MRI scans is one of the principal outstanding problems in the MRI research community. Towards this goal, we hosted the second fastMRI competition targeted towards reconstructing MR images with subsampled k-space data. We provided participants with data from 7,299 clinical brain scans (de-identified via a HIPAA-compliant procedure by NYU Langone Health), holding back the fully-sampled data from 894 of these scans for challenge evaluation purposes. In contrast to the 2019 challenge, we focused our radiologist evaluations on pathological assessment in brain images. We also debuted a new Transfer track that required participants to submit models evaluated on MRI scanners from outside the training set. We received 19 submissions from eight different groups. Results showed one team scoring best in both SSIM scores and qualitative radiologist evaluations. We also performed analysis on alternative metrics to mitigate the effects of background noise and collected feedback from the participants to inform future challenges. Lastly, we identify common failure modes across the submissions, highlighting areas of need for future research in the MRI reconstruction community. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/cf.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Cold fusing sequence-to-sequence models with language models (Patent)</strong> <br />
  <em><small>Anuroop Sriram, Heewoo Jun, Sanjeev Satheesh, Adam Coates </small></em><br />
  <small><b>US Patent 10,867,595</b></small> 
  <br/>

  
  
  
  
  <a href="https://patentimages.storage.googleapis.com/c4/81/5b/58ceaa1a6771c8/US10867595.pdf" target="_blank"><button class="btn-common">PATENT</button></a> 
   <a data-toggle="collapse" href="#_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="_abs"><div class="well-abstract">
<small> <p align="justify"> Described herein are systems and methods for generating natural language sentences with Sequence-to-sequence (Seq2Seq) models with attention. The Seq2Seq models may be implemented in applications, such as machine translation, image captioning, and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language models. Disclosed herein are ‚ÄúCold Fusion‚Äù architecture embodiments that leverage a pre-trained language model during training. The Seq2Seq models with Cold Fusion embodiments are able to better utilize language information enjoying faster convergence, better generalization, and almost complete transfer to a new domain while using less labeled training data. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/mls.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> MLS: A Large-Scale Multilingual Dataset for Speech Research</strong> <br />
  <em><small>Vineel Pratap, Qiantong Xu, Anuroop Sriram, Gabriel Synnaeve, Ronan Collobert </small></em><br />
  <small><b>Interspeech 2020</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2012.03411" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#pratapMLS_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="pratapMLS_abs">ABSTRACT</a>
  <a href="https://github.com/flashlight/wav2letter/tree/main/recipes/mls" target="_blank"><button class="btn-common">CODE</button></a> 
  <a href="http://openslr.org/94" target="_blank"><button class="btn-common">DATA</button></a> 
  
  


<br/>
<div class="collapse" id="pratapMLS_abs"><div class="well-abstract">
<small> <p align="justify"> This paper introduces Multilingual LibriSpeech (MLS) dataset, a large multilingual corpus suitable for speech research. The dataset is derived from read audiobooks from LibriVox and consists of 8 languages, including about 44.5K hours of English and a total of about 6K hours for other languages. Additionally, we provide Language Models (LM) and baseline Automatic Speech Recognition (ASR) models and for all the languages in our dataset. We believe such a large transcribed dataset will open new avenues in ASR and Text-To-Speech (TTS) research. The dataset will be made freely available for anyone at this http URL. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/3t.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Using deep learning to accelerate knee MRI at 3 T: results of an interchangeability study</strong> <br />
  <em><small>Michael P Recht, Jure Zbontar, Daniel K Sodickson, Florian Knoll, Nafissa Yakubova, Anuroop Sriram, Tullie Murrell, Aaron Defazio, Michael Rabbat, Leon Rybak et al. </small></em><br />
  <small><b>American Journal of Roentgenology (AJR)</b></small> 
  <br/>

  
  
  <a href="https://www.ajronline.org/doi/10.2214/AJR.20.23313" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#rechtInterch_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="rechtInterch_abs">ABSTRACT</a>
  
  
  
   <a data-toggle="collapse" href="#rechtInterch_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="rechtInterch_press">MEDIA</a>


<br/>
<div class="collapse" id="rechtInterch_abs"><div class="well-abstract">
<small> <p align="justify"> &lt;b&gt;OBJECTIVE&lt;/b&gt; &lt;br/&gt;Deep learning (DL) image reconstruction has the potential to disrupt the current state of MRI by significantly decreasing the time required for MRI examinations. Our goal was to use DL to accelerate MRI to allow a 5-minute comprehensive examination of the knee without compromising image quality or diagnostic accuracy.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;MATERIALS AND METHODS&lt;/b&gt; &lt;br/&gt;A DL model for image reconstruction using a variational network was optimized. The model was trained using dedicated multisequence training, in which a single reconstruction model was trained with data from multiple sequences with different contrast and orientations. After training, data from 108 patients were retrospectively undersampled in a manner that would correspond with a net 3.49-fold acceleration of fully sampled data acquisition and a 1.88-fold acceleration compared with our standard twofold accelerated parallel acquisition. An interchangeability study was performed, in which the ability of six readers to detect internal derangement of the knee was compared for clinical and DL-accelerated images.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;RESULTS&lt;/b&gt; &lt;br/&gt;We found a high degree of interchangeability between standard and DL-accelerated images. In particular, results showed that interchanging the sequences would produce discordant clinical opinions no more than 4% of the time for any feature evaluated. Moreover, the accelerated sequence was judged by all six readers to have better quality than the clinical sequence.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;CONCLUSION&lt;/b&gt; &lt;br/&gt;An optimized DL model allowed acceleration of knee images that performed interchangeably with standard images for detection of internal derangement of the knee. Importantly, readers preferred the quality of accelerated images to that of standard clinical images. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="rechtInterch_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://ai.facebook.com/blog/fastmri-breakthrough-shows-ai-accelerated-mris-interchangeable-with-slow-traditional-mris/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/fair.webp');"> 
      "FastMRI breakthrough shows AI-accelerated MRIs interchangeable with traditional MRIs"
       by Nafissa Yakubova, Anuroop Sriram, Jure Zbontar, Mike Rabbat, Aaron Defazio, Mark Tygert, Larry Zitnick
    </li>
    </a>
  
    <a href="https://nyulangone.org/news/new-research-finds-fastmri-scans-generated-artificial-intelligence-are-accurate-traditional-mri" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/nyu_langone.webp');"> 
      "New Research Finds FastMRI Scans Generated with Artificial Intelligence Are as Accurate as Traditional MRI"
      
    </li>
    </a>
  
    <a href="https://www.wsj.com/articles/researchers-at-facebook-ai-nyu-langone-push-speed-limits-of-mri-11597755600" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/wsj.webp');"> 
      "Researchers at Facebook AI, NYU Langone Push Speed Limits of MRI"
      
    </li>
    </a>
  
    <a href="https://techcrunch.com/2020/08/18/blind-test-shows-ai-enhanced-mri-scans-are-just-as-good-but-4-times-faster/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/techcrunch.webp');"> 
      "Blind test shows AI-enhanced MRI scans are just as good but 4 times faster"
       by Devin Coldewey
    </li>
    </a>
  
    <a href="https://www.dailymail.co.uk/sciencetech/article-8639049/Facebook-AI-creates-MRI-images-four-times-faster-normal.html" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/dailymail.webp');"> 
      "Facebook AI takes MRI images four times faster than normal by &#39;recreating missing parts&#39; - and experts can&#39;t tell the difference"
       by Ryan Morrison
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/fmri_chall.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Advancing machine learning for MR image reconstruction with an open competition: Overview of the 2019 fastMRI challenge</strong> <br />
  <em><small>Florian Knoll, Tullie Murrell, Anuroop Sriram, Nafissa Yakubova, Jure Zbontar, Michael Rabbat, Aaron Defazio, Matthew J Muckley, Daniel K Sodickson, C Lawrence Zitnick et al. </small></em><br />
  <small><b>Magnetic Resonance in Medicine (MRM)</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2001.02518" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#knollFastmri2019_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="knollFastmri2019_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="knollFastmri2019_abs"><div class="well-abstract">
<small> <p align="justify"> &lt;b&gt;Purpose:&lt;/b&gt;&lt;br/&gt;To advance research in the field of machine learning for MR image reconstruction with an open challenge.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Methods:&lt;/b&gt;&lt;br/&gt;We provided participants with a dataset of raw k-space data from 1,594 consecutive clinical exams of the knee. The goal of the challenge was to reconstruct images from these data. In order to strike a balance between realistic data and a shallow learning curve for those not already familiar with MR image reconstruction, we ran multiple tracks for multi-coil and single-coil data. We performed a two-stage evaluation based on quantitative image metrics followed by evaluation by a panel of radiologists. The challenge ran from June to December of 2019.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Results:&lt;/b&gt;&lt;br/&gt;We received a total of 33 challenge submissions. All participants chose to submit results from supervised machine learning approaches.&lt;br/&gt;&lt;br/&gt; &lt;b&gt;Conclusion:&lt;/b&gt;&lt;br/&gt;The challenge led to new developments in machine learning for image reconstruction, provided insight into the current state of the art in the field, and highlighted remaining hurdles for clinical adoption. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/ec_white.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> An introduction to electrocatalyst design using machine learning for renewable energy storage</strong> <br />
  <em><small>C Lawrence Zitnick, Lowik Chanussot, Abhishek Das, Siddharth Goyal, Javier Heras-Domingo, Caleb Ho, Weihua Hu, Thibaut Lavril, Aini Palizhati, Morgane Riviere et al. </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2010.09435" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#zitnickOcpwhitepaper_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="zitnickOcpwhitepaper_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="zitnickOcpwhitepaper_abs"><div class="well-abstract">
<small> <p align="justify"> Scalable and cost-effective solutions to renewable energy storage are essential to addressing the world&#39;s rising energy needs while reducing climate change. As we increase our reliance on renewable energy sources such as wind and solar, which produce intermittent power, storage is needed to transfer power from times of peak generation to peak demand. This may require the storage of power for hours, days, or months. One solution that offers the potential of scaling to nation-sized grids is the conversion of renewable energy to other fuels, such as hydrogen or methane. To be widely adopted, this process requires cost-effective solutions to running electrochemical reactions. An open challenge is finding low-cost electrocatalysts to drive these reactions at high rates. Through the use of quantum mechanical simulations (density functional theory), new catalyst structures can be tested and evaluated. Unfortunately, the high computational cost of these simulations limits the number of structures that may be tested. The use of machine learning may provide a method to efficiently approximate these calculations, leading to new approaches in finding effective electrocatalysts. In this paper, we provide an introduction to the challenges in finding suitable electrocatalysts, how machine learning may be applied to the problem, and the use of the Open Catalyst Project OC20 dataset for model training. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/varnet.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> End-to-end variational networks for accelerated MRI reconstruction</strong> <br />
  <em><small>Anuroop Sriram, Jure Zbontar, Tullie Murrell, Aaron Defazio, C Lawrence Zitnick, Nafissa Yakubova, Florian Knoll, Patricia Johnson </small></em><br />
  <small><b>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2020</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2004.06688" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramVarNet_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramVarNet_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/fastMRI/tree/main/fastmri_examples/varnet" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="sriramVarNet_abs"><div class="well-abstract">
<small> <p align="justify"> The slow acquisition speed of magnetic resonance imaging (MRI) has led to the development of two complementary methods: acquiring multiple views of the anatomy simultaneously (parallel imaging) and acquiring fewer samples than necessary for traditional signal processing methods (compressed sensing). While the combination of these methods has the potential to allow much faster scan times, reconstruction from such undersampled multi-coil data has remained an open problem. In this paper, we present a new approach to this problem that extends previously proposed variational methods by learning fully end-to-end. Our method obtains new state-of-the-art results on the fastMRI dataset for both brain and knee MRIs. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/mmasr.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters</strong> <br />
  <em><small>Vineel Pratap, Anuroop Sriram, Paden Tomasello, Awni Hannun, Vitaliy Liptchinsky, Gabriel Synnaeve, Ronan Collobert </small></em><br />
  <small><b>Interspeech 2020</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/2007.03001" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#pratapMassively_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="pratapMassively_abs">ABSTRACT</a>
  
  
  
   <a data-toggle="collapse" href="#pratapMassively_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="pratapMassively_press">MEDIA</a>


<br/>
<div class="collapse" id="pratapMassively_abs"><div class="well-abstract">
<small> <p align="justify"> We study training a single acoustic model for multiple languages with the aim of improving automatic speech recognition (ASR) performance on low-resource languages, and over-all simplifying deployment of ASR systems that support diverse languages. We perform an extensive benchmark on 51 languages, with varying amount of training data by language(from 100 hours to 1100 hours). We compare three variants of multilingual training from a single joint model without knowing the input language, to using this information, to multiple heads (one per language cluster). We show that multilingual training of ASR models on several languages can improve recognition performance, in particular, on low resource languages. We see 20.9%, 23% and 28.8% average WER relative reduction compared to monolingual baselines on joint model, joint model with language input and multi head model respectively. To our knowledge, this is the first work studying multilingual ASR at massive scale, with more than 50 languages and more than 16,000 hours of audio across them. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="pratapMassively_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://venturebeat.com/ai/facebooks-speech-recognition-model-supports-51-different-languages/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/venturebeat.webp');"> 
      "Facebook&#39;s speech recognition model supports 51 different languages"
       by Kyle Wiggers
    </li>
    </a>
  
    <a href="https://voicebot.ai/2020/07/09/facebook-builds-speech-recognition-engine-combining-51-languages-in-one-model/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/voicebot.webp');"> 
      "Facebook Builds Speech Recognition Engine Combining 51 Languages in One Model"
       by Eric Hal Schwartz
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/bias.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Systems and methods for principled bias reduction in production speech models (Patent)</strong> <br />
  <em><small>Eric Battenberg, Rewon Child, Adam Coates, Christopher Fougner, Yashesh Gaur, Jiaji Huang, Heewoo Jun, Ajay Kannan, Markus Kliegl, Atul Kumar et al. </small></em><br />
  <small><b>US Patent 10,657,955</b></small> 
  <br/>

  
  
  
  
  <a href="https://patentimages.storage.googleapis.com/c3/2c/2b/b9a0d1cdbe25d0/US10657955.pdf" target="_blank"><button class="btn-common">PATENT</button></a> 
   <a data-toggle="collapse" href="#_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="_abs"><div class="well-abstract">
<small> <p align="justify"> Described herein are systems and methods to identify and address sources of bias in an end-to-end speech model. In one or more embodiments, the end-to-end model may be a recurrent neural network with two 2D-convolutional input layers, followed by multiple bidirectional recurrent layers and one fully connected layer before a softmax layer. In one or more embodiments, the network is trained end-to-end using the CTC loss function to directly predict sequences of characters from log spectrograms of audio. With optimized recurrent layers and training together with alignment information, some unwanted bias induced by using purely forward only recurrences may be removed in a deployed model. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/fastmri.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> fastMRI: A publicly available raw k-space and DICOM dataset of knee images for accelerated MR image reconstruction using machine learning</strong> <br />
  <em><small>Florian Knoll, Jure Zbontar, Anuroop Sriram, Matthew J Muckley, Mary Bruno, Aaron Defazio, Marc Parente, Krzysztof J Geras, Joe Katsnelson, Hersh Chandarana et al. </small></em><br />
  <small><b>Radiology: Artificial Intelligence</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1811.08839" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#knollFastmri_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="knollFastmri_abs">ABSTRACT</a>
  <a href="https://github.com/facebookresearch/fastMRI/" target="_blank"><button class="btn-common">CODE</button></a> 
  <a href="https://fastmri.med.nyu.edu/" target="_blank"><button class="btn-common">DATA</button></a> 
  
   <a data-toggle="collapse" href="#knollFastmri_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="knollFastmri_press">MEDIA</a>


<br/>
<div class="collapse" id="knollFastmri_abs"><div class="well-abstract">
<small> <p align="justify"> Accelerating Magnetic Resonance Imaging (MRI) by taking fewer measurements has the potential to reduce medical costs, minimize stress to patients and make MRI possible in applications where it is currently prohibitively slow or expensive. We introduce the fastMRI dataset, a large-scale collection of both raw MR measurements and clinical MR images, that can be used for training and evaluation of machine-learning approaches to MR image reconstruction. By introducing standardized evaluation criteria and a freely-accessible dataset, our goal is to help the community make rapid advances in the state of the art for MR image reconstruction. We also provide a self-contained introduction to MRI for machine learning researchers with no medical imaging background. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="knollFastmri_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://techcrunch.com/2018/08/20/nyu-and-facebook-team-up-to-supercharge-mri-scans-with-ai/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/techcrunch.webp');"> 
      "NYU and Facebook team up to supercharge MRI scans with AI"
       by Devin Coldewey
    </li>
    </a>
  
    <a href="https://www.theverge.com/2020/8/18/21373335/faster-mri-scans-ai-machine-learning-facebook-nyu-research-clinical-study" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/verge.webp');"> 
      "Facebook and NYU use artificial intelligence to make MRI scans four times faster"
       by James Vincent
    </li>
    </a>
  
    <a href="https://www.zdnet.com/article/facebook-nyu-aim-to-use-ai-to-speed-up-mri-scans/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/zdnet.webp');"> 
      "Facebook, NYU aim to use AI to speed up MRI scans"
       by Larry Dignan
    </li>
    </a>
  
    <a href="https://www.popsci.com/artificial-intelligence-fast-mri-scans-facebook-nyu/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/popularscience.webp');"> 
      "An exclusive look at Facebook‚Äôs efforts to speed up MRI scans using artificial intelligence"
       by Rob Verger
    </li>
    </a>
  
    <a href="https://www.cnet.com/tech/tech-industry/facebook-and-nyu-want-to-use-ai-to-make-mri-exams-faster/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/cnet.webp');"> 
      "Facebook and NYU want to use AI to make MRI exams faster"
       by Marrian Zhou
    </li>
    </a>
  
    <a href="https://www.usatoday.com/story/tech/news/2018/08/21/facebook-nyu-artificial-intelligence-mri-scans/1049904002/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/usatoday.webp');"> 
      "Facebook, NYU team up to make MRI scans faster through AI"
       by Mike Snider
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/grappanet.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> GrappaNet: Combining parallel imaging with deep learning for multi-coil MRI reconstruction</strong> <br />
  <em><small>Anuroop Sriram, Jure Zbontar, Tullie Murrell, C Lawrence Zitnick, Aaron Defazio, Daniel K Sodickson </small></em><br />
  <small><b>Conference on Computer Vision and Pattern Recognition (CVPR) 2019</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1910.12325" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramGrappaNet_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramGrappaNet_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="sriramGrappaNet_abs"><div class="well-abstract">
<small> <p align="justify"> Magnetic Resonance Image (MRI) acquisition is an inherently slow process which has spurred the development of two different acceleration methods: acquiring multiple correlated samples simultaneously (parallel imaging) and acquiring fewer samples than necessary for traditional signal processing methods (compressed sensing). Both methods provide complementary approaches to accelerating the speed of MRI acquisition. In this paper, we present a novel method to integrate traditional parallel imaging methods into deep neural networks that is able to generate high quality reconstructions even for high acceleration factors. The proposed method, called GrappaNet, performs progressive reconstruction by first mapping the reconstruction problem to a simpler one that can be solved by a traditional parallel imaging methods using a neural network, followed by an application of a parallel imaging method, and finally fine-tuning the output with another neural network. The entire network can be trained end-to-end. We present experimental results on the recently released fastMRI dataset and show that GrappaNet can generate higher quality reconstructions than competing methods for both 4√ó and 8√ó acceleration. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2019</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/asr_ssup.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> End-to-end asr: from supervised to semi-supervised learning with modern architectures</strong> <br />
  <em><small>Gabriel Synnaeve, Qiantong Xu, Jacob Kahn, Tatiana Likhomanenko, Edouard Grave, Vineel Pratap, Anuroop Sriram, Vitaliy Liptchinsky, Ronan Collobert </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1911.08460" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#synnaeveE2EASR_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="synnaeveE2EASR_abs">ABSTRACT</a>
  <a href="https://github.com/flashlight/wav2letter/tree/main/recipes/sota/2019" target="_blank"><button class="btn-common">CODE</button></a> 
  
  
  


<br/>
<div class="collapse" id="synnaeveE2EASR_abs"><div class="well-abstract">
<small> <p align="justify"> We study pseudo-labeling for the semi-supervised training of ResNet, Time-Depth Separable ConvNets, and Transformers for speech recognition, with either CTC or Seq2Seq loss functions. We perform experiments on the standard LibriSpeech dataset, and leverage additional unlabeled data from LibriVox through pseudo-labeling. We show that while Transformer-based acoustic models have superior performance with the supervised dataset alone, semi-supervision improves all models across architectures and loss functions and bridges much of the performance gaps between them. In doing so, we reach a new state-of-the-art for end-to-end acoustic models decoded with an external language model in the standard supervised learning setting, and a new absolute state-of-the-art with semi-supervised training. Finally, we study the effect of leveraging different amounts of unlabeled audio, propose several ways of evaluating the characteristics of unlabeled audio which improve acoustic modeling, and show that acoustic models trained with more audio rely less on external language models. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/rnnt.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> RNN-T for latency controlled ASR with improved beam search</strong> <br />
  <em><small>Mahaveer Jain, Kjell Schubert, Jay Mahadeokar, Ching-Feng Yeh, Kaustubh Kalgaonkar, Anuroop Sriram, Christian Fuegen, Michael L Seltzer </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1911.01629" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#jainRNNT_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="jainRNNT_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="jainRNNT_abs"><div class="well-abstract">
<small> <p align="justify"> Neural transducer-based systems such as RNN Transducers (RNN-T) for automatic speech recognition (ASR) blend the individual components of a traditional hybrid ASR systems (acoustic model, language model, punctuation model, inverse text normalization) into one single model. This greatly simplifies training and inference and hence makes RNN-T a desirable choice for ASR systems. In this work, we investigate use of RNN-T in applications that require a tune-able latency budget during inference time. We also improved the decoding speed of the originally proposed RNN-T beam search algorithm. We evaluated our proposed system on English videos ASR dataset and show that neural RNN-T models can achieve comparable WER and better computational efficiency compared to a well tuned hybrid ASR baseline. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2018</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/rsgan.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Robust speech recognition using generative adversarial networks</strong> <br />
  <em><small>Anuroop Sriram, Heewoo Jun, Yashesh Gaur, Sanjeev Satheesh </small></em><br />
  <small><b>IEEE international conference on acoustics, speech and signal processing (ICASSP) 2018</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1711.01567" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramRobustGAN_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramRobustGAN_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="sriramRobustGAN_abs"><div class="well-abstract">
<small> <p align="justify"> This paper describes a general, scalable, end-to-end framework that uses the generative adversarial network (GAN) objective to enable robust speech recognition. Encoders trained with the proposed approach enjoy improved invariance by learning to map noisy audio to the same embedding space as that of clean audio. Unlike previous methods, the new framework does not rely on domain expertise or simplifying assumptions as are often needed in signal processing, and directly encourages robustness in a data-driven way. We show the new approach improves simulated far-field speech recognition of vanilla sequence-to-sequence models without specialized front-ends or preprocessing. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/cf.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Cold Fusion: Training Seq2Seq Models Together with Language Models</strong> <br />
  <em><small>Anuroop Sriram, Heewoo Jun, Sanjeev Satheesh, Adam Coates </small></em><br />
  <small><b>Interspeech 2018</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1708.06426" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#sriramFusion_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramFusion_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="sriramFusion_abs"><div class="well-abstract">
<small> <p align="justify"> Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2017</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/transducers.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Exploring neural transducers for end-to-end speech recognition</strong> <br />
  <em><small>Eric Battenberg, Jitong Chen, Rewon Child, Adam Coates, Yashesh Gaur Yi Li, Hairong Liu, Sanjeev Satheesh, Anuroop Sriram, Zhenyao Zhu </small></em><br />
  <small><b>Automatic Speech Recognition and Understanding (ASRU) 2017</b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1707.07413" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#battenbergTransducers_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="battenbergTransducers_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="battenbergTransducers_abs"><div class="well-abstract">
<small> <p align="justify"> In this work, we perform an empirical comparison among the CTC, RNN-Transducer, and attention-based Seq2Seq models for end-to-end speech recognition. We show that, without any language model, Seq2Seq and RNN-Transducer models both outperform the best reported CTC models with a language model, on the popular Hub5&#39;00 benchmark. On our internal diverse dataset, these trends continue - RNNTransducer models rescored with a language model after beam search outperform our best CTC models. These results simplify the speech recognition pipeline so that decoding can now be expressed purely as neural network operations. We also study how the choice of encoder architecture affects the performance of the three models - when all encoder layers are forward only, and when encoders downsample the input representation aggressively. </p> </small>
</div></div>




</li>
</ul>

</div>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/bias.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Reducing bias in production speech models</strong> <br />
  <em><small>Eric Battenberg, Rewon Child, Adam Coates, Christopher Fougner, Yashesh Gaur, Jiaji Huang, Heewoo Jun, Ajay Kannan, Markus Kliegl, Atul Kumar et al. </small></em><br />
  <small><b></b></small> 
  <br/>

  
  <a href="https://arxiv.org/abs/1705.04400" target="_blank"><button class="btn-common">ARXIV</button></a> 
  
  
  
   <a data-toggle="collapse" href="#battenbergBias_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="battenbergBias_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="battenbergBias_abs"><div class="well-abstract">
<small> <p align="justify"> Replacing hand-engineered pipelines with end-to-end deep learning systems has enabled strong results in applications like speech and object recognition. However, the causality and latency constraints of production systems put end-to-end speech models back into the underfitting regime and expose biases in the model that we show cannot be overcome by scaling up, i.e., training bigger models on more data. In this work we systematically identify and address sources of bias, reducing error rates by up to 20% while remaining practical for deployment. We achieve this by utilizing improved neural architectures for streaming inference, solving optimization issues, and employing strategies that increase audio and label modelling versatility. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
      <h2>2016</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/ds2.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Deep speech 2: End-to-end speech recognition in english and mandarin</strong> <br />
  <em><small>Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang Chen et al. </small></em><br />
  <small><b>International conference on machine learning (ICML) 2016</b></small> 
  <br/>

  
  
  <a href="https://proceedings.mlr.press/v48/amodei16.pdf" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#amodeiDS2_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="amodeiDS2_abs">ABSTRACT</a>
  
  
  
   <a data-toggle="collapse" href="#amodeiDS2_press" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="amodeiDS2_press">MEDIA</a>


<br/>
<div class="collapse" id="amodeiDS2_abs"><div class="well-abstract">
<small> <p align="justify"> We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech--two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, resulting in a 7x speedup over our previous system. Because of this efficiency, experiments that previously took weeks now run in days. This enables us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale. </p> </small>
</div></div>



<small>
<br/>
<div class="collapse" id="amodeiDS2_press">
<div class="well-abstract">
  <ul style="padding:-20px;list-style-position:outside;">
  
    <a href="https://www.technologyreview.com/2015/12/16/9846/baidus-deep-learning-system-rivals-people-at-speech-recognition/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/mittechreview.webp');"> 
      "Baidu‚Äôs Deep-Learning System Rivals People at Speech Recognition"
       by Will Knight
    </li>
    </a>
  
    <a href="https://techcrunch.com/2016/06/11/google-baidu-and-the-race-for-an-edge-in-the-global-speech-recognition-market/" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/techcrunch.webp');"> 
      "Google, Baidu and the race for an edge in the global speech recognition market"
       by Daniel Faggella
    </li>
    </a>
  
    <a href="https://mashable.com/article/baidu-deep-speech-2-fast-speech-recognition" target="_blank"> 
    <li style="list-style-image:url('../static/images/logos/mashable.webp');"> 
      "This speech recognition software is much faster than human typists"
       by Carmen Triola
    </li>
    </a>
  
  </ul>
</div>
</div>
</small>


</li>
</ul>

</div>
      
    
  
    
    
    
  
    
    
    
  
    
    
    
      <h2>2013</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/fred.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> FRED (A Framework for Reconstructing Epidemic Dynamics): an open-source software system for modeling infectious diseases and control strategies using census-based populations</strong> <br />
  <em><small>John J Grefenstette, Shawn T Brown, Roni Rosenfeld, Jay DePasse, Nathan TB Stone, Phillip C Cooley, William D Wheaton, Alona Fyshe, David D Galloway, Anuroop Sriram et al. </small></em><br />
  <small><b>BMC public health</b></small> 
  <br/>

  
  
  <a href="https://bmcpublichealth.biomedcentral.com/articles/10.1186/1471-2458-13-940" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#grefFRED_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="grefFRED_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="grefFRED_abs"><div class="well-abstract">
<small> <p align="justify"> Background&lt;br/&gt;&lt;br/&gt; Mathematical and computational models provide valuable tools that help public health planners to evaluate competing health interventions, especially for novel circumstances that cannot be examined through observational or controlled studies, such as pandemic influenza. The spread of diseases like influenza depends on the mixing patterns within the population, and these mixing patterns depend in part on local factors including the spatial distribution and age structure of the population, the distribution of size and composition of households, employment status and commuting patterns of adults, and the size and age structure of schools. Finally, public health planners must take into account the health behavior patterns of the population, patterns that often vary according to socioeconomic factors such as race, household income, and education levels.&lt;br/&gt;&lt;br/&gt; Results&lt;br/&gt; FRED (a Framework for Reconstructing Epidemic Dynamics) is a freely available open-source agent-based modeling system based closely on models used in previously published studies of pandemic influenza. This version of FRED uses open-access census-based synthetic populations that capture the demographic and geographic heterogeneities of the population, including realistic household, school, and workplace social networks. FRED epidemic models are currently available for every state and county in the United States, and for selected international locations.&lt;br/&gt;&lt;br/&gt; Conclusions&lt;br/&gt; State and county public health planners can use FRED to explore the effects of possible influenza epidemics in specific geographic regions of interest and to help evaluate the effect of interventions such as vaccination programs and school closure policies. FRED is available under a free open source license in order to contribute to the development of better modeling tools and to encourage open discussion of modeling tools being used to evaluate public health policies. We also welcome participation by other researchers in the further development of FRED. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
      <h2>2009</h2>
      

<div class="well-sm">
<ul class="flex-container">
<li class="flex-item1">
  
   <img src="../static/images/pubpic/bc.webp" class="img-responsive" width="200%" style="float: left" />
  
</li>
<li class="flex-item2">
  <strong> Evaluating centrality metrics in real-world networks on GPU</strong> <br />
  <em><small>Anuroop Sriram, Kollu Gautham, Kishore Kothapalli, P J Narayan, R Govindarajulu </small></em><br />
  <small><b>IEEE International Conference on High Performance Computing (HiPC 2009)</b></small> 
  <br/>

  
  
  <a href="https://hipc.org/hipc2009/documents/HIPCSS09Papers/1569256361.pdf" target="_blank"><button class="btn-common"> PAPER</button></a> 
  
  
   <a data-toggle="collapse" href="#sriramCentrality_abs" class="btn-common" style="text-decoration:none; hover:#ebebeb;" role="button" aria-expanded="false" aria-controls="sriramCentrality_abs">ABSTRACT</a>
  
  
  
  


<br/>
<div class="collapse" id="sriramCentrality_abs"><div class="well-abstract">
<small> <p align="justify"> GPGPU has received a lot of attention recently as a cost effective solution for high performance computing. In this paper we present a parallel algorithm for computing Betweenness centrality (BC) using CUDA. BC is an important metric in small world network analysis which is expensive to compute. While there are existing parallel implementations, ours is the first implementation on commodity hardware. Our algorithm exploits parallelism at multiple levels of granularity to achieve good performance. We conduct several experiments to show that the algorithm gives considerable speedup over sequential algorithms. We also provide a detailed analysis of the performance of the algorithm. </p> </small>
</div></div>




</li>
</ul>

</div>
      
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  
    
    
    
  


</div>

      </div>
    </div>

    <br/>
<div id="footer" class="panel">
  <div class="panel-footer">
    <div class="container-fluid">
      <div class="row">
        <div class="col-sm-4">
          <p>&copy; 2022 Anuroop Sriram</p>
          <p></p>
        </div>

        <div class="col-sm-4">
          <p></p>
        </div>

        <div class="col-sm-4">
          <p></p>
        </div>
      </div>
    </div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="../static/js/bootstrap.min.js"></script>
<script src="../static/js/theme.js"></script>
  </body>
</html>